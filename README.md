# MCP RunCmd

Servidor **MCP (Model Context Protocol)** para **LM Studio** que permite ejecutar comandos del sistema y scripts de Python de forma controlada.  

Este servidor expone varias herramientas como:
- `run_cmd` â†’ Ejecutar comandos en shell.
- `list_dir` â†’ Listar directorios.
- `read_text` â†’ Leer archivos de texto.
- `write_text` â†’ Escribir archivos de texto.
- `run_python_file` â†’ Ejecutar scripts Python existentes.
- `run_python` â†’ Ejecutar cÃ³digo Python inline.

---

## ğŸš€ InstalaciÃ³n

1. Clona este repositorio:
   ```bash
   git clone https://github.com/TU_USUARIO/mcp-run-cmd.git
   cd mcp-run-cmd
   ```

2. Instala dependencias:
   ```bash
   pip install -r requirements.txt
   ```

---

## â–¶ï¸ Uso

Ejecuta el servidor:

```bash
python runCmd.py
```

---

## âš™ï¸ IntegraciÃ³n con LM Studio

En tu archivo `mcp.json` de configuraciÃ³n de LM Studio, aÃ±ade una entrada como esta:

```json
{
  "name": "MCP RunCmd",
  "description": "Servidor MCP para ejecutar comandos y scripts desde LM Studio",
  "binary": "python",
  "args": ["runCmd.py"],
  "env": {},
  "autoStart": true
}
```

Guarda este archivo junto a `runCmd.py` y LM Studio detectarÃ¡ el servidor automÃ¡ticamente.

---

## ğŸ“‚ Archivos principales

- `runCmd.py` â†’ Servidor MCP con las herramientas.
- `requirements.txt` â†’ Dependencias necesarias.
- `README.md` â†’ DocumentaciÃ³n bÃ¡sica del proyecto.
- `mcp.json` â†’ ConfiguraciÃ³n de ejemplo para LM Studio.

---

## ğŸ“œ Licencia
MIT
